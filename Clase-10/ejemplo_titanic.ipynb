{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Componentes Principales (PCA) en el conjunto de datos del Titanic\n",
    "\n",
    "El análisis de componentes principales (PCA) es una técnica de reducción de dimensionalidad que se utiliza para transformar un conjunto de datos en un nuevo sistema de coordenadas, donde las variables originales se expresan en términos de componentes principales no correlacionados. Esto es especialmente útil cuando se trata de conjuntos de datos con muchas características (dimensiones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Preprocesamiento de datos\n",
    "\n",
    "Carga de datos: Carga el conjunto de datos del Titanic en un DataFrame utilizando una biblioteca como pandas en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga el conjunto de datos\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de datos: Maneja los valores faltantes y atípicos en el conjunto de datos. Puedes imputar valores faltantes con la media o la mediana y eliminar valores atípicos utilizando técnicas como el método IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputa valores faltantes con la mediana\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Elimina valores atípicos utilizando el método IQR\n",
    "Q1 = data['Fare'].quantile(0.25)\n",
    "Q3 = data['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data[(data['Fare'] >= Q1 - 1.5 * IQR) & (data['Fare'] <= Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificación de variables categóricas: Convierte las variables categóricas en variables numéricas utilizando la codificación one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación one-hot de variables categóricas\n",
    "data_encoded = pd.get_dummies(data, columns=['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización de características: Normaliza las características para que tengan media cero y desviación estándar uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Inicializa el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajusta el escalador a los datos y transforma las características\n",
    "scaled_features = scaler.fit_transform(data_encoded[['Age', 'Fare', 'Pclass', 'SibSp', 'Parch']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 2: Cálculo de PCA\n",
    "\n",
    "Cálculo de la matriz de covarianza: Calcula la matriz de covarianza de las características normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calcula la matriz de covarianza\n",
    "cov_matrix = np.cov(scaled_features, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00129199,  0.08582635, -0.35005884, -0.33543273, -0.20444529],\n",
       "       [ 0.08582635,  1.00129199, -0.5905382 ,  0.37086645,  0.33727968],\n",
       "       [-0.35005884, -0.5905382 ,  1.00129199,  0.11409018,  0.08355915],\n",
       "       [-0.33543273,  0.37086645,  0.11409018,  1.00129199,  0.41071228],\n",
       "       [-0.20444529,  0.33727968,  0.08355915,  0.41071228,  1.00129199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los autovalores y autovectores: Calcula los autovalores y autovectores de la matriz de covarianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula los autovalores y autovectores\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección de componentes principales: Ordena los autovalores de mayor a menor y selecciona los primeros componentes principales que explican la mayor parte de la varianza acumulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena los autovalores en orden descendente\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "\n",
    "# Calcula la varianza acumulada\n",
    "total_variance = np.sum(sorted_eigenvalues)\n",
    "explained_variance_ratio = sorted_eigenvalues / total_variance\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Transformación de datos\n",
    "\n",
    "Construcción de la matriz de proyección: Construye la matriz de proyección utilizando los autovectores seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona los primeros k autovectores (donde k es el número de componentes principales deseados)\n",
    "num_components = 2  # Por ejemplo, selecciona los 2 primeros componentes principales\n",
    "selected_eigenvectors = eigenvectors[:, sorted_indices[:num_components]]\n",
    "\n",
    "# Construye la matriz de proyección\n",
    "projection_matrix = selected_eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformación de datos: Multiplica la matriz de datos preprocesados por la matriz de proyección para obtener los datos transformados en el espacio de componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma los datos originales en el espacio de componentes principales\n",
    "transformed_data = np.dot(scaled_features, projection_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: Análisis e interpretación\n",
    "\n",
    "Exploración de componentes principales: Examina los componentes principales y sus valores asociados para entender qué características originales contribuyen más a cada componente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componente principal 1: [-0.23880555  0.54747575 -0.15235618  0.57438715  0.53861787]\n",
      "Importancia de variables: [-0.44157875  1.0123452  -0.28172399  1.06210746  0.99596597]\n",
      "Componente principal 2: [-0.53298877 -0.43265652  0.67417223  0.22342326  0.15590111]\n",
      "Importancia de variables: [-0.91362739 -0.74164197  1.15563825  0.38298295  0.26723926]\n"
     ]
    }
   ],
   "source": [
    "# Imprime los autovectores (componentes principales) junto con la importancia de cada variable\n",
    "for i, component in enumerate(selected_eigenvectors.T):\n",
    "    print(f\"Componente principal {i + 1}: {component}\")\n",
    "    print(f\"Importancia de variables: {component * sorted_eigenvalues[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varianza explicada: Calcula la varianza explicada por cada componente principal y la varianza acumulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza explicada por el componente principal 1: 0.3693\n",
      "Varianza acumulada hasta el componente principal 1: 0.3693\n",
      "Varianza explicada por el componente principal 2: 0.3424\n",
      "Varianza acumulada hasta el componente principal 2: 0.7117\n",
      "Varianza explicada por el componente principal 3: 0.1359\n",
      "Varianza acumulada hasta el componente principal 3: 0.8476\n",
      "Varianza explicada por el componente principal 4: 0.1069\n",
      "Varianza acumulada hasta el componente principal 4: 0.9546\n",
      "Varianza explicada por el componente principal 5: 0.0454\n",
      "Varianza acumulada hasta el componente principal 5: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Imprime la varianza explicada por cada componente principal y la varianza acumulada\n",
    "for i, explained_var in enumerate(explained_variance_ratio):\n",
    "    print(f\"Varianza explicada por el componente principal {i + 1}: {explained_var:.4f}\")\n",
    "    print(f\"Varianza acumulada hasta el componente principal {i + 1}: {cumulative_variance_ratio[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
